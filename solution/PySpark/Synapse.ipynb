{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\r\n",
        "import json\r\n",
        "from pyspark.sql import Row\r\n",
        "from pyspark.sql.types import *\r\n",
        "from pyspark.sql.functions import *\r\n",
        "session_id = random.randint(0,1000000)\r\n",
        "\r\n",
        "TaskObject = '''    {\r\n",
        "        \"TaskInstanceId\": 20,\r\n",
        "        \"TaskMasterId\": -2,\r\n",
        "        \"TaskStatus\": \"InProgress\",\r\n",
        "        \"TaskType\": \"Azure Storage to SQL Database\",\r\n",
        "        \"Enabled\": 1,\r\n",
        "        \"ExecutionUid\": \"b829721c-f297-49eb-8436-c33e27005971\",\r\n",
        "        \"NumberOfRetries\": 0,\r\n",
        "        \"DegreeOfCopyParallelism\": 1,\r\n",
        "        \"KeyVaultBaseUrl\": \"https://mst-stg-kv-ads-pnu0.vault.azure.net/\",\r\n",
        "        \"ScheduleMasterId\": \"4\",\r\n",
        "        \"TaskGroupConcurrency\": \"10\",\r\n",
        "        \"TaskGroupPriority\": 0,\r\n",
        "        \"TaskExecutionType\": \"ADF\",\r\n",
        "        \"DataFactory\": {\r\n",
        "            \"Id\": 1,\r\n",
        "            \"Name\": \"mst-stg-adf-ads-pnu0\",\r\n",
        "            \"ResourceGroup\": \"adsgftera2\",\r\n",
        "            \"SubscriptionId\": \"035a1364-f00d-48e2-b582-4fe125905ee3\",\r\n",
        "            \"ADFPipeline\": \"GPL_AzureBlobFS_Parquet_AzureSqlTable_NA_Azure\",\r\n",
        "            \"TaskDatafactoryIR\": \"Azure\"\r\n",
        "        },\r\n",
        "        \"Source\": {\r\n",
        "            \"System\": {\r\n",
        "                \"SystemId\": 4,\r\n",
        "                \"SystemServer\": \"https://mststgdlsadspnu0adsl.dfs.core.windows.net\",\r\n",
        "                \"AuthenticationType\": \"MSI\",\r\n",
        "                \"Type\": \"ADLS\",\r\n",
        "                \"Username\": null,\r\n",
        "                \"Container\": \"datalakeraw\"\r\n",
        "            },\r\n",
        "            \"Instance\": {\r\n",
        "                \"SourceRelativePath\": \"samples/\"\r\n",
        "            },\r\n",
        "            \"DataFileName\": \"SalesLT.Customer.chunk_1.parquet\",\r\n",
        "            \"DeleteAfterCompletion\": \"false\",\r\n",
        "            \"MaxConcurrentConnections\": 0,\r\n",
        "            \"Recursively\": \"false\",\r\n",
        "            \"RelativePath\": \"samples/\",\r\n",
        "            \"Type\": \"Parquet\"\r\n",
        "        },\r\n",
        "        \"Target\": {\r\n",
        "            \"System\": {\r\n",
        "                \"SystemId\": 4,\r\n",
        "                \"SystemServer\": \"https://mststgdlsadspnu0adsl.dfs.core.windows.net\",\r\n",
        "                \"AuthenticationType\": \"MSI\",\r\n",
        "                \"Type\": \"ADLS\",\r\n",
        "                \"Username\": null,\r\n",
        "                \"Container\": \"datalakeraw\"\r\n",
        "            },\r\n",
        "            \"Instance\": {\r\n",
        "                \"SourceRelativePath\": \"samples/\"\r\n",
        "            },\r\n",
        "            \"DataFileName\": \"SalesLT-Customer-Delta\",\r\n",
        "            \"DeleteAfterCompletion\": \"false\",\r\n",
        "            \"MaxConcurrentConnections\": 0,\r\n",
        "            \"Recursively\": \"false\",\r\n",
        "            \"RelativePath\": \"deltalake/samples/\",\r\n",
        "            \"Type\": \"Delta\"\r\n",
        "        }\r\n",
        "    }'''\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mststgsynspads",
              "session_id": 6,
              "statement_id": 50,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-30T06:52:06.5635532Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-30T06:52:06.6739693Z",
              "execution_finish_time": "2022-01-30T06:52:06.8331387Z"
            },
            "text/plain": "StatementMeta(mststgsynspads, 6, 50, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 48,
      "metadata": {
        "tags": [
          "parameters"
        ]
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "TaskObjectJson = json.loads(TaskObject)\r\n",
        "Source = TaskObjectJson['Source']['System']['Container'] + \"@\" + TaskObjectJson['Source']['System']['SystemServer'].replace(\"https://\",\"\") + \"/\"\r\n",
        "Target = TaskObjectJson['Target']['System']['Container'] + \"@\" + TaskObjectJson['Target']['System']['SystemServer'].replace(\"https://\",\"\") + \"/\"\r\n",
        "\r\n",
        "Source = Source + TaskObjectJson['Source']['RelativePath'] + \"/\" + TaskObjectJson['Source']['DataFileName']\r\n",
        "Target = Target + TaskObjectJson['Target']['RelativePath'] + \"/\" + TaskObjectJson['Target']['DataFileName']\r\n",
        "\r\n",
        "#remove any double slashes\r\n",
        "Source.replace('//', '')\r\n",
        "TargetContainer.replace('//', '')\r\n",
        "\r\n",
        "#add abfss\r\n",
        "Source = \"abfss://\" + Source\r\n",
        "Target = \"abfss://\" + Target\r\n",
        "\r\n",
        "print (Source)\r\n",
        "print (Target)\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mststgsynspads",
              "session_id": 6,
              "statement_id": 51,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-30T06:52:35.8865705Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-30T06:52:35.9853277Z",
              "execution_finish_time": "2022-01-30T06:52:36.1473039Z"
            },
            "text/plain": "StatementMeta(mststgsynspads, 6, 51, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abfss://datalakeraw@mststgdlsadspnu0adsl.dfs.core.windows.net/samples//SalesLT.Customer.chunk_1.parquet\nabfss://datalakeraw@mststgdlsadspnu0adsl.dfs.core.windows.net/deltalake/samples//SalesLT-Customer-Delta"
          ]
        }
      ],
      "execution_count": 49,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from delta.tables import *\r\n",
        "df = spark.read.load(Source, format='parquet')\r\n",
        "sql = 'describe detail \"' + Target + '\"'\r\n",
        "if (spark.sql(sql).collect()[0].asDict()['format'] == 'delta'):\r\n",
        "    print(\"Table already exists. Performing Merge\")\r\n",
        "    olddt = DeltaTable.forPath(spark, Target)\r\n",
        "    (olddt\r\n",
        "    .alias(\"oldData\") \r\n",
        "    .merge(df.alias(\"newData\"), \"oldData.CustomerID = newData.CustomerID\")\r\n",
        "    .whenMatchedUpdate(set = {\"FirstName\": col(\"newData.FirstName\")})\r\n",
        "    .whenNotMatchedInsert(values = {\"CustomerID\": col(\"newData.CustomerID\"), \"FirstName\":\r\n",
        "                                    col(\"newData.FirstName\")})\r\n",
        "    .execute()\r\n",
        "    )\r\n",
        "else:\r\n",
        "    print(\"Table does not exist.\")    \r\n",
        "    df.write.format(\"delta\").save(Target)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mststgsynspads",
              "session_id": 6,
              "statement_id": 68,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-30T07:24:13.6709259Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-30T07:24:13.9553966Z",
              "execution_finish_time": "2022-01-30T07:24:45.178489Z"
            },
            "text/plain": "StatementMeta(mststgsynspads, 6, 68, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table already exists. Performing Merge"
          ]
        }
      ],
      "execution_count": 66,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "olddt.history().show(20, 1000, False)\r\n",
        "\r\n",
        "#spark.sql(\"CREATE TABLE SalesLTCustomer USING DELTA LOCATION '{0}'\".format(TargetFile))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mststgsynspads",
              "session_id": 6,
              "statement_id": 69,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-30T07:25:45.2010536Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-30T07:25:45.3082354Z",
              "execution_finish_time": "2022-01-30T07:25:48.0996087Z"
            },
            "text/plain": "StatementMeta(mststgsynspads, 6, 69, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+------+--------+---------+------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|version|          timestamp|userId|userName|operation|                                         operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|                                                                                                                                                                                                  operationMetrics|\n+-------+-------------------+------+--------+---------+------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|      1|2022-01-30 07:24:40|  null|    null|    MERGE|[predicate -> (oldData.`CustomerID` = newData.`CustomerID`)]|null|    null|     null|          0|          null|        false|[numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 200, numTargetRowsInserted -> 0, numTargetRowsUpdated -> 847, numOutputRows -> 847, numSourceRows -> 847, numTargetFilesRemoved -> 1]|\n|      0|2022-01-30 06:53:10|  null|    null|    WRITE|                  [mode -> ErrorIfExists, partitionBy -> []]|null|    null|     null|       null|          null|         true|                                                                                                                                                    [numFiles -> 1, numOutputBytes -> 89560, numOutputRows -> 847]|\n+-------+-------------------+------+--------+---------+------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+"
          ]
        }
      ],
      "execution_count": 67,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute Upsert\r\n",
        "(old_deltaTable\r\n",
        " .alias(\"oldData\") \r\n",
        " .merge(newIncrementalData.alias(\"newData\"), \"oldData.id = newData.id\")\r\n",
        " .whenMatchedUpdate(set = {\"name\": col(\"newData.name\")})\r\n",
        " .whenNotMatchedInsert(values = {\"id\": col(\"newData.id\"), \"name\":\r\n",
        "                                col(\"newData.name\")})\r\n",
        " .execute()\r\n",
        ")\r\n",
        "\r\n",
        "# Display the records to check if the records are Merged\r\n",
        "display(spark.read.format(\"delta\").load(\"/data/events_old/\"))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}